{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, 'sqft_living15':float, \n",
    "              'grade':int, 'yr_renovated':int, 'price':float, 'bedrooms':float, 'zipcode':str, \n",
    "              'long':float, 'sqft_lot15':float, 'sqft_living':float, 'floors':str, 'condition':int, \n",
    "              'lat':float, 'date':str, 'sqft_basement':int, 'yr_built':int, 'id':str, 'sqft_lot':int, \n",
    "              'view':int}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./data/kc_house_train_data.csv', dtype=dtype_dict, index_col=0)\n",
    "test_data = pd.read_csv('./data/kc_house_test_data.csv', dtype=dtype_dict, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we often think of multiple regression as including multiple different features (e.g. # of bedrooms, square feet, and # of bathrooms) but we can also consider transformations of existing variables e.g. the log of the square feet or even \"interaction\" variables such as the product of bedrooms and bathrooms. Add 4 new variables in both your train_data and test_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['bedrooms_squared'] = train_data.bedrooms**2\n",
    "train_data['bed_bath_rooms']   = train_data.bedrooms * train_data.bathrooms\n",
    "train_data['log_sqft_living']  = np.log(train_data.sqft_living)\n",
    "train_data['lat_plus_long']    = train_data.lat + train_data.long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['bedrooms_squared'] = test_data.bedrooms**2\n",
    "test_data['bed_bath_rooms']   = test_data.bedrooms * test_data.bathrooms\n",
    "test_data['log_sqft_living']  = np.log(test_data.sqft_living)\n",
    "test_data['lat_plus_long']    = test_data.lat + test_data.long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we continue let’s explain these new variables:\n",
    "\n",
    "- Squaring bedrooms will increase the separation between not many bedrooms (e.g. 1) and lots of bedrooms (e.g. 4) since 1^2 = 1 but 4^2 = 16. Consequently this variable will mostly affect houses with many bedrooms.\n",
    "- Bedrooms times bathrooms is what's called an \"interaction\" variable. It is large when both of them are large.\n",
    "- Taking the log of square feet has the effect of bringing large values closer together and spreading out small values.\n",
    "- Adding latitude to longitude is non-sensical but we will do it anyway (you'll see why)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bedrooms_squared    12.446678\n",
       "bed_bath_rooms       7.503902\n",
       "log_sqft_living      7.550275\n",
       "lat_plus_long      -74.653334\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.loc[:, ['bedrooms_squared', 'bed_bath_rooms', \n",
    "                  'log_sqft_living', 'lat_plus_long']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use graphlab.linear_regression.create (or any other regression library/function) to estimate the regression coefficients/weights for predicting ‘price’ for the following three models:(In all 3 models include an intercept -- most software does this by default).\n",
    "\n",
    "- Model 1: ‘sqft_living’, ‘bedrooms’, ‘bathrooms’, ‘lat’, and ‘long’\n",
    "- Model 2: ‘sqft_living’, ‘bedrooms’, ‘bathrooms’, ‘lat’,‘long’, and ‘bed_bath_rooms’\n",
    "- Model 3: ‘sqft_living’, ‘bedrooms’, ‘bathrooms’, ‘lat’,‘long’, ‘bed_bath_rooms’, ‘bedrooms_squared’, ‘log_sqft_living’, and ‘lat_plus_long’\n",
    "\n",
    "You’ll note that the three models here are “nested” in that all of the features of the Model 1 are in Model 2 and all of the features of Model 2 are in Model 3.\n",
    "\n",
    "Learn all three models on the TRAINING data set. Save your model results for quiz questions later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors1 = ['sqft_living', 'bedrooms', 'bathrooms', 'lat', 'long']\n",
    "fit1 = LinearRegression().fit(X=train_data.loc[:, predictors1], y=train_data.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sqft_living': 312.25864627320277,\n",
       " 'bedrooms': -59586.53315361201,\n",
       " 'bathrooms': 15706.742082734603,\n",
       " 'lat': 658619.2639305174,\n",
       " 'long': -309374.35126823315}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(predictors1, fit1.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors2 = predictors1 + ['bed_bath_rooms']\n",
    "fit2 = LinearRegression().fit(X=train_data.loc[:, predictors2], y=train_data.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sqft_living': 306.6100534589952,\n",
       " 'bedrooms': -113446.36807020311,\n",
       " 'bathrooms': -71461.30829275977,\n",
       " 'lat': 654844.6295033027,\n",
       " 'long': -294298.96913811873,\n",
       " 'bed_bath_rooms': 25579.652000752216}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(predictors2, fit2.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors3 = predictors2 + ['bedrooms_squared', 'log_sqft_living', 'lat_plus_long']\n",
    "fit3 = LinearRegression().fit(X=train_data.loc[:, predictors3], y=train_data.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sqft_living': 529.4228196465249,\n",
       " 'bedrooms': 34514.229577990445,\n",
       " 'bathrooms': 67060.7813189112,\n",
       " 'lat': 534085.6108674955,\n",
       " 'long': -406750.71086103976,\n",
       " 'bed_bath_rooms': -8570.504394630156,\n",
       " 'bedrooms_squared': -6788.586670340485,\n",
       " 'log_sqft_living': -561831.4840755223,\n",
       " 'lat_plus_long': 127334.90000645655}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(predictors3, fit3.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using your three estimated models compute the RSS (Residual Sum of Squares) on the Training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "967879963049546.4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((train_data.price - fit1.predict(train_data.loc[:,predictors1]))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "958419635074069.2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((train_data.price - fit2.predict(train_data.loc[:,predictors2]))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "903436455050479.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((train_data.price - fit3.predict(train_data.loc[:,predictors3]))**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using your three estimated models compute the RSS on the Testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225500469795490.16"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((test_data.price - fit1.predict(test_data.loc[:,predictors1]))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223377462976466.88"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((test_data.price - fit2.predict(test_data.loc[:,predictors2]))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259236319207179.44"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((test_data.price - fit3.predict(test_data.loc[:,predictors3]))**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next write a function that takes a data set, a list of features (e.g. [‘sqft_living’, ‘bedrooms’]), to be used as inputs, and a name of the output (e.g. ‘price’). This function should return a features_matrix (2D array) consisting of first a column of ones followed by columns containing the values of the input features in the data set in the same order as the input list. It should also return an output_array which is an array of the values of the output in the data set (e.g. ‘price’). e.g. if you’re using SFrames and numpy you can complete the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_data(df, features, output):\n",
    "    df['constant'] = 1 # add a constant column to an DataFrame\n",
    "    features = ['constant'] + features\n",
    "    df_features = df.loc[:, features]\n",
    "    features_matrix = df_features.values\n",
    "    output_array = df.loc[:, output].values\n",
    "    return features_matrix, output_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the features matrix (including a column of 1s for the constant) is stored as a 2D array (or matrix) and the regression weights are stored as a 1D array then the predicted output is just the dot product between the features matrix and the weights (with the weights on the right). Write a function ‘predict_output’ which accepts a 2D array ‘feature_matrix’ and a 1D array ‘weights’ and returns a 1D array ‘predictions’. e.g. in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_outcome(feature_matrix, weights):\n",
    "    predictions = feature_matrix @ weights\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a the values of a single input feature in an array ‘feature’ and the prediction ‘errors’ (predictions - output) then the derivative of the regression cost function with respect to the weight of ‘feature’ is just twice the dot product between ‘feature’ and ‘errors’. Write a function that accepts a ‘feature’ array and ‘error’ array and returns the ‘derivative’ (a single number). e.g. in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):\n",
    "    derivative = 2 * np.dot(errors, feature)\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use our predict_output and feature_derivative to write a gradient descent function. Although we can compute the derivative for all the features simultaneously (the gradient) we will explicitly loop over the features individually for simplicity. Write a gradient descent function that does the following:\n",
    "\n",
    "- Accepts a numpy feature_matrix 2D array, a 1D output array, an array of initial weights, a step size and a convergence tolerance.\n",
    "- While not converged updates each feature weight by subtracting the step size times the derivative for that feature given the current weights\n",
    "- At each step computes the magnitude/length of the gradient (square root of the sum of squared components)\n",
    "- When the magnitude of the gradient is smaller than the input tolerance returns the final weight vector.\n",
    "\n",
    "e.g. if you’re using SFrames and numpy you can complete the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_gradient_descent(feature_matrix, output, initial_weights, step_size, tolerance):\n",
    "    converged = False\n",
    "    weights = np.array(initial_weights)\n",
    "    while not converged:\n",
    "        # compute the predictions based on feature_matrix and weights:\n",
    "        predictions = predict_outcome(feature_matrix, weights)\n",
    "        # compute the errors as predictions - output:\n",
    "        errors = predictions - output\n",
    "        gradient_sum_squares = 0 # initialize the gradient\n",
    "        # while not converged, update each weight individually:\n",
    "        for i in range(len(weights)):\n",
    "            # Recall that feature_matrix[:, i] is the feature column associated with weights[i]\n",
    "            # compute the derivative for weight[i]:\n",
    "            derivative_i = feature_derivative(errors, feature_matrix[:,i])\n",
    "            # add the squared derivative to the gradient magnitude\n",
    "            gradient_sum_squares += (derivative_i**2)\n",
    "            # update the weight based on step size and derivative:\n",
    "            weights[i] -= (step_size * derivative_i)\n",
    "        gradient_magnitude = np.sqrt(gradient_sum_squares)\n",
    "        if gradient_magnitude < tolerance:\n",
    "            converged = True\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will run the regression_gradient_descent function on some actual data. In particular we will use the gradient descent to estimate the model from Week 1 using just an intercept and slope. Use the following parameters:\n",
    "\n",
    "- features: ‘sqft_living’\n",
    "- output: ‘price’\n",
    "- initial weights: -47000, 1 (intercept, sqft_living respectively)\n",
    "- step_size = 7e-12\n",
    "- tolerance = 2.5e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_features = ['sqft_living']\n",
    "my_output = 'price'\n",
    "simple_feature_matrix, output = get_numpy_data(train_data, simple_features, my_output)\n",
    "initial_weights = np.array([-47000., 1.])\n",
    "step_size = 7e-12\n",
    "tolerance = 2.5e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_weights = regression_gradient_descent(simple_feature_matrix, output,initial_weights, \n",
    "                                             step_size, tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'constant': -46999.88716554671, 'sqft_living': 281.91211917520917}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(['constant']+simple_features, simple_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build a corresponding ‘test_simple_feature_matrix’ and ‘test_output’ using test_data. Using ‘test_simple_feature_matrix’ and ‘simple_weights’ compute the predicted house prices on all the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_simple_feature_matrix, test_output = get_numpy_data(test_data, simple_features, my_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_hat_simple = test_simple_feature_matrix @ simple_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356134.4432550024"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_hat_simple[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute RSS on all test data for this model. Record the value and store it for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275,400,044,902,128.3\n"
     ]
    }
   ],
   "source": [
    "RSS_simple = np.sum((test_output - price_hat_simple)**2)\n",
    "print('{:,}'.format(RSS_simple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use the gradient descent to fit a model with more than 1 predictor variable (and an intercept). Use the following parameters:\n",
    "\n",
    "- model features = ‘sqft_living’, ‘sqft_living_15’\n",
    "- output = ‘price’\n",
    "- initial weights = \\[-100000, 1, 1\\] (intercept, sqft_living, and sqft_living_15 respectively)\n",
    "- step size = 4e-12\n",
    "- tolerance = 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features = ['sqft_living', 'sqft_living15']\n",
    "my_output = 'price'\n",
    "feature_matrix, output = get_numpy_data(train_data, model_features,my_output)\n",
    "initial_weights = np.array([-100000., 1., 1.])\n",
    "step_size = 4e-12\n",
    "tolerance = 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_weights = regression_gradient_descent(feature_matrix, output,initial_weights, \n",
    "                                            step_size, tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'constant': -99999.96884887619,\n",
       " 'sqft_living': 245.0726034645802,\n",
       " 'sqft_living15': 65.27952669888786}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(['constant']+model_features, multi_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the regression weights from this second model (using sqft_living and sqft_living_15) and predict the outcome of all the house prices on the TEST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_multi_feature_matrix, test_output = get_numpy_data(test_data, model_features, my_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_hat_multi = test_multi_feature_matrix @ multi_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366651.4116294939"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_hat_multi[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310000.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270,263,443,629,803.56\n"
     ]
    }
   ],
   "source": [
    "RSS_multi = np.sum((test_output - price_hat_multi)**2)\n",
    "print('{:,}'.format(RSS_multi))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
